{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS540-2.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BsovcWHTCW8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87oy1YUrDv1B",
        "colab_type": "code",
        "outputId": "1d930dda-b9ce-44f7-ff56-7f7ad2cce14e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "data = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/datasets/news_summary_more.csv\",encoding=\"utf-8\")\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headlines</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>upGrad learner switches to career in ML &amp; Al w...</td>\n",
              "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Delhi techie wins free food from Swiggy for on...</td>\n",
              "      <td>Kunal Shah's credit card bill payment platform...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>New Zealand end Rohit Sharma-led India's 12-ma...</td>\n",
              "      <td>New Zealand defeated India by 8 wickets in the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Aegon life iTerm insurance plan helps customer...</td>\n",
              "      <td>With Aegon Life iTerm Insurance plan, customer...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Have known Hirani for yrs, what if MeToo claim...</td>\n",
              "      <td>Speaking about the sexual harassment allegatio...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           headlines                                               text\n",
              "0  upGrad learner switches to career in ML & Al w...  Saurav Kant, an alumnus of upGrad and IIIT-B's...\n",
              "1  Delhi techie wins free food from Swiggy for on...  Kunal Shah's credit card bill payment platform...\n",
              "2  New Zealand end Rohit Sharma-led India's 12-ma...  New Zealand defeated India by 8 wickets in the...\n",
              "3  Aegon life iTerm insurance plan helps customer...  With Aegon Life iTerm Insurance plan, customer...\n",
              "4  Have known Hirani for yrs, what if MeToo claim...  Speaking about the sexual harassment allegatio..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEwOonSKlmTx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "\n",
        "                           \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "\n",
        "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
        "\n",
        "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
        "\n",
        "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
        "\n",
        "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
        "\n",
        "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
        "\n",
        "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
        "\n",
        "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
        "\n",
        "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
        "\n",
        "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
        "\n",
        "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
        "\n",
        "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
        "\n",
        "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
        "\n",
        "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
        "\n",
        "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
        "\n",
        "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
        "\n",
        "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "\n",
        "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
        "\n",
        "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
        "\n",
        "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "\n",
        "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
        "\n",
        "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgttCkv2EJDt",
        "colab_type": "code",
        "outputId": "75509c43-5929-40d9-f4ca-9f8b36710e1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "def preprocess(text):\n",
        "    text = text.lower() # lowercase\n",
        "    text = text.split() # convert have'nt -> have not\n",
        "    for i in range(len(text)):\n",
        "        word = text[i]\n",
        "        if word in contraction_mapping:\n",
        "            text[i] = contraction_mapping[word]\n",
        "    text = \" \".join(text)\n",
        "    text = text.split()\n",
        "    newtext = []\n",
        "    for word in text:\n",
        "        if word not in stop_words:\n",
        "            newtext.append(word)\n",
        "    text = \" \".join(newtext)\n",
        "    text = text.replace(\"'s\",'') # convert your's -> your\n",
        "    text = re.sub(r'\\(.*\\)','',text) # remove (words)\n",
        "    text = re.sub(r'[^a-zA-Z0-9. ]','',text) # remove punctuations\n",
        "    text = re.sub(r'\\.',' . ',text)\n",
        "    return text\n",
        "\n",
        "sample = \"(hello) hi there .man tiger caller who's that isn't it ? WALL-E\"\n",
        "print(preprocess(sample))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            " hi  . man tiger caller  walle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14uXn9nWEYS5",
        "colab_type": "code",
        "outputId": "e3f89b72-b719-4fd2-8b16-4f5dcf5925a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "data['headlines'] = data['headlines'].apply(lambda x:preprocess(x))\n",
        "data['text'] = data['text'].apply(lambda x:preprocess(x))\n",
        "print(data['headlines'][20],data['text'][20])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "think opposition even dreams me pm modi claiming dearth ideas among opposition parties prime minister narendra modi wednesday said the opposition talks modi whole day suspect even dream me .  pm modi addressing new india youth conclave in surat added opposition parties one agenda modi . \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2julEYdBoEhm",
        "colab_type": "code",
        "outputId": "3a8e265d-f985-400a-b8e1-d37a6bc90280",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "x = data['text']\n",
        "y = data['headlines']\n",
        "print(x[50],y[50],sep='\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "former finance minister yashwant sinha tuesday demanded probe alleged diversion loans worth 31000 crore dewan housing finance  .  agencies including regulators government failed track nefarious deals said .  comes media report tuesday accused dhfl controlling shareholders diverting funds shell companies buy assets . \n",
            "yashwant sinha demands probe alleged fund diversion dhfl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sS4W1tzoLfq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1_igQgBoP9S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUERHa55oToI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def readLangs(text, summary, reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        "    \n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[text[i],summary[i]] for i in range(len(text))]\n",
        "\n",
        "    # Reverse pairs, make Lang instances\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(summary)\n",
        "        output_lang = Lang(text)\n",
        "    else:\n",
        "        input_lang = Lang(text)\n",
        "        output_lang = Lang(summary)\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJpcstO2oV4B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepareData(lang1, lang2, reverse=False):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHyzwCSCoYEI",
        "colab_type": "code",
        "outputId": "6e53dff1-6206-4350-d808-0d1480a958ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "source": [
        "input_lang, output_lang, pairs = prepareData( x, y , False)\n",
        "print(random.choice(pairs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading lines...\n",
            "Read 98401 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "0        saurav kant alumnus upgrad iiitb pg program ma...\n",
            "1        kunal shah credit card bill payment platform c...\n",
            "2        new zealand defeated india 8 wickets fourth od...\n",
            "3        aegon life iterm insurance plan customers enjo...\n",
            "4        speaking sexual harassment allegations rajkuma...\n",
            "                               ...                        \n",
            "98396    crpf jawan tuesday axed death sharpedged weapo...\n",
            "98397    uff yeh first song sonakshi sinha starrer upco...\n",
            "98398    according reports new version 1999 science fic...\n",
            "98399    new music video shows rapper snoop dogg aiming...\n",
            "98400    madhesi morcha alliance seven political partie...\n",
            "Name: text, Length: 98401, dtype: object 100293\n",
            "0        upgrad learner switches career ml  al 90 salar...\n",
            "1         delhi techie wins free food swiggy one year cred\n",
            "2        new zealand end rohit sharmaled india 12match ...\n",
            "3        aegon life iterm insurance plan helps customer...\n",
            "4                 known hirani yrs metoo claims true sonam\n",
            "                               ...                        \n",
            "98396           crpf jawan axed death maoists chhattisgarh\n",
            "98397        first song sonakshi sinha noor titled uff yeh\n",
            "98398                   the matrix film get reboot reports\n",
            "98399    snoop dogg aims gun clown dressed trump new video\n",
            "98400    madhesi morcha withdraws support nepalese gove...\n",
            "Name: headlines, Length: 98401, dtype: object 41363\n",
            "['actor akshay kumar took social media share first look sets upcoming film gold .  film revolve around independent india first gold medal 1948 olympic games .  also starring television actress mouni roy film directed reema kagti .  scheduled release august 15 2018 . ', 'akshay shares first look sets sports film gold']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-FEVkSNoaRw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "MAX_LENGTH = 90\n",
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UyJagTSoigO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Y6QNoj4oqIt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rc5AH-61oxg2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDy0Hr9Co3J1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yawaB6uCo5ZN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    print(\"Training....\")\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        if iter% 1000 == 0:\n",
        "            print(iter,\"/\",n_iters + 1)\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    return showPlot(plot_losses)\n",
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]\n",
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heoo9v0fo-ck",
        "colab_type": "code",
        "outputId": "efdcd296-6813-44ae-da72-79fc9d432069",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "hidden_size = 512\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "iterations=150000\n",
        "trainIters(encoder1, attn_decoder1, iterations, print_every=(iterations//15))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training....\n",
            "1000 / 150001\n",
            "2000 / 150001\n",
            "3000 / 150001\n",
            "4000 / 150001\n",
            "5000 / 150001\n",
            "6000 / 150001\n",
            "7000 / 150001\n",
            "8000 / 150001\n",
            "9000 / 150001\n",
            "10000 / 150001\n",
            "18m 11s (- 254m 45s) (10000 6%) 7.1003\n",
            "11000 / 150001\n",
            "12000 / 150001\n",
            "13000 / 150001\n",
            "14000 / 150001\n",
            "15000 / 150001\n",
            "16000 / 150001\n",
            "17000 / 150001\n",
            "18000 / 150001\n",
            "19000 / 150001\n",
            "20000 / 150001\n",
            "36m 15s (- 235m 39s) (20000 13%) 7.0353\n",
            "21000 / 150001\n",
            "22000 / 150001\n",
            "23000 / 150001\n",
            "24000 / 150001\n",
            "25000 / 150001\n",
            "26000 / 150001\n",
            "27000 / 150001\n",
            "28000 / 150001\n",
            "29000 / 150001\n",
            "30000 / 150001\n",
            "54m 31s (- 218m 7s) (30000 20%) 6.8869\n",
            "31000 / 150001\n",
            "32000 / 150001\n",
            "33000 / 150001\n",
            "34000 / 150001\n",
            "35000 / 150001\n",
            "36000 / 150001\n",
            "37000 / 150001\n",
            "38000 / 150001\n",
            "39000 / 150001\n",
            "40000 / 150001\n",
            "72m 54s (- 200m 29s) (40000 26%) 6.6572\n",
            "41000 / 150001\n",
            "42000 / 150001\n",
            "43000 / 150001\n",
            "44000 / 150001\n",
            "45000 / 150001\n",
            "46000 / 150001\n",
            "47000 / 150001\n",
            "48000 / 150001\n",
            "49000 / 150001\n",
            "50000 / 150001\n",
            "91m 16s (- 182m 32s) (50000 33%) 6.4538\n",
            "51000 / 150001\n",
            "52000 / 150001\n",
            "53000 / 150001\n",
            "54000 / 150001\n",
            "55000 / 150001\n",
            "56000 / 150001\n",
            "57000 / 150001\n",
            "58000 / 150001\n",
            "59000 / 150001\n",
            "60000 / 150001\n",
            "109m 22s (- 164m 3s) (60000 40%) 6.2435\n",
            "61000 / 150001\n",
            "62000 / 150001\n",
            "63000 / 150001\n",
            "64000 / 150001\n",
            "65000 / 150001\n",
            "66000 / 150001\n",
            "67000 / 150001\n",
            "68000 / 150001\n",
            "69000 / 150001\n",
            "70000 / 150001\n",
            "127m 31s (- 145m 44s) (70000 46%) 6.0936\n",
            "71000 / 150001\n",
            "72000 / 150001\n",
            "73000 / 150001\n",
            "74000 / 150001\n",
            "75000 / 150001\n",
            "76000 / 150001\n",
            "77000 / 150001\n",
            "78000 / 150001\n",
            "79000 / 150001\n",
            "80000 / 150001\n",
            "145m 36s (- 127m 24s) (80000 53%) 5.8795\n",
            "81000 / 150001\n",
            "82000 / 150001\n",
            "83000 / 150001\n",
            "84000 / 150001\n",
            "85000 / 150001\n",
            "86000 / 150001\n",
            "87000 / 150001\n",
            "88000 / 150001\n",
            "89000 / 150001\n",
            "90000 / 150001\n",
            "163m 46s (- 109m 11s) (90000 60%) 5.7131\n",
            "91000 / 150001\n",
            "92000 / 150001\n",
            "93000 / 150001\n",
            "94000 / 150001\n",
            "95000 / 150001\n",
            "96000 / 150001\n",
            "97000 / 150001\n",
            "98000 / 150001\n",
            "99000 / 150001\n",
            "100000 / 150001\n",
            "181m 59s (- 90m 59s) (100000 66%) 5.5960\n",
            "101000 / 150001\n",
            "102000 / 150001\n",
            "103000 / 150001\n",
            "104000 / 150001\n",
            "105000 / 150001\n",
            "106000 / 150001\n",
            "107000 / 150001\n",
            "108000 / 150001\n",
            "109000 / 150001\n",
            "110000 / 150001\n",
            "200m 6s (- 72m 46s) (110000 73%) 5.4771\n",
            "111000 / 150001\n",
            "112000 / 150001\n",
            "113000 / 150001\n",
            "114000 / 150001\n",
            "115000 / 150001\n",
            "116000 / 150001\n",
            "117000 / 150001\n",
            "118000 / 150001\n",
            "119000 / 150001\n",
            "120000 / 150001\n",
            "218m 16s (- 54m 34s) (120000 80%) 5.3996\n",
            "121000 / 150001\n",
            "122000 / 150001\n",
            "123000 / 150001\n",
            "124000 / 150001\n",
            "125000 / 150001\n",
            "126000 / 150001\n",
            "127000 / 150001\n",
            "128000 / 150001\n",
            "129000 / 150001\n",
            "130000 / 150001\n",
            "236m 33s (- 36m 23s) (130000 86%) 5.2924\n",
            "131000 / 150001\n",
            "132000 / 150001\n",
            "133000 / 150001\n",
            "134000 / 150001\n",
            "135000 / 150001\n",
            "136000 / 150001\n",
            "137000 / 150001\n",
            "138000 / 150001\n",
            "139000 / 150001\n",
            "140000 / 150001\n",
            "254m 48s (- 18m 12s) (140000 93%) 5.2277\n",
            "141000 / 150001\n",
            "142000 / 150001\n",
            "143000 / 150001\n",
            "144000 / 150001\n",
            "145000 / 150001\n",
            "146000 / 150001\n",
            "147000 / 150001\n",
            "148000 / 150001\n",
            "149000 / 150001\n",
            "150000 / 150001\n",
            "273m 1s (- 0m 0s) (150000 100%) 5.2005\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4P69MJBpCyr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "def BLEU(encoder, attention_decoder, n_examples):\n",
        "    total_score = 0\n",
        "    evaluate_pairs = [random.choice(pairs) for i in range(n_examples)]\n",
        "    for pair in evaluate_pairs:\n",
        "        input_sentence = pair[0]\n",
        "        target_words = [pair[1]]\n",
        "        output_words, _ = evaluate(encoder, attention_decoder, input_sentence)\n",
        "        output_words = output_words\n",
        "        score = sentence_bleu(target_words, output_words)\n",
        "        total_score += score\n",
        "    average_BLEU = total_score/len(pairs)\n",
        "    return average_BLEU"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--voIv-WtC1w",
        "colab_type": "code",
        "outputId": "f61d4ed7-7554-42a2-ad51-b0d243935265",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "BLEUScore = BLEU(encoder1, attn_decoder1, 5000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARlJMGmH0bTx",
        "colab_type": "code",
        "outputId": "9a7feee3-65a2-47f6-b7f3-c74c8a4d1eec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "evaluateRandomly(encoder1, attn_decoder1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> eman ahmed egyptian woman came india weightloss treatment lost 242 kg two months dr muffazal lakdawala saifee hospital said .  36yearold weighs 262 kg almost 50 less weighed earlier added .  rapid weight loss drastically improved functioning organs dr lakdawala said . \n",
            "= egyptian woman eman ahmed lost 242 kg 2 months\n",
            "< lost lost lost 2 months months months <EOS>\n",
            "\n",
            "> delhi police registered fir spicejet chairman md ajay singh seven directors cheating case .  delhibased private consultant alleged used services aviation sector pay fees .  the complainant defrauded company filing frivolous complaints extract money spicejet said . \n",
            "= delhi consultant accuses spicejet md cheating police file fir\n",
            "< paytm booked cheating cheating cheating case <EOS>\n",
            "\n",
            "> actor abhishek bachchan set star filmmaker priyadarshan upcoming film tentatively titled bachchan singh described something along lines mr .  india mask .  film written rumi jaffrey fantasy fiction film abhishek plays corrupt cop turns saviour sorts powers . \n",
            "= abhishek star mr .  indialike film bachchan singh\n",
            "< abhishek bachchan star abhishek b film <EOS>\n",
            "\n",
            "> wang xing founder chairman ceo chinese food delivery neighbourhood services giant meituan dianping saw net worth surge 5 . 3 billion company ipo .  39yearold owns 10 . 44 stake company whose market value reached nearly 51 billion .  beijingbased company raised 4 . 2 billion hong kong secondbiggest technology ipo year xiaomi . \n",
            "= 39yrold chinese founder wealth jumps 5 . 3bn ipo\n",
            "< china firm firm firm firm firm firm <EOS>\n",
            "\n",
            "> million muslims mostly women signed petition moved rssaffiliated muslim rashtriya manch  practice triple talaq .  the representatives state government must come sit together start debate muslim women claim human status mrm stated . \n",
            "= 10 lakh muslims sign rss petition triple talaq\n",
            "< triple talaq muslim triple talaq muslim <EOS>\n",
            "\n",
            "> several sanitation workers east delhi municipal corporation decided go indefinite strike wednesday demand release pending salaries .  workers threatened gherao edmc headquarters also put lock it .  reportedly corporation budgetary deficit paid workers since september . \n",
            "= delhi sanitation workers go strike pending salaries\n",
            "< delhi workers demand pay strike demand demand <EOS>\n",
            "\n",
            "> former indian cricketer rahul dravid donned goalkeeping gloves friendly game football playing indian football team captain sunil chhetri side saturday .  event part citywide talent identification program bengaluru yearlong scholarships handed out .  match chhetri scored past dravid later said that going bio . \n",
            "= dravid turns goalkeeper plays friendly vs sunil chhetri\n",
            "< dravid dravid indian football captain <EOS>\n",
            "\n",
            "> saturn largest moon titan energy resources support human civilisation size us new research suggests .  titan thick atmosphere protect surface radiation liquid surface could drive underwater turbines tides .  further shifting sand dunes suggest wind power could generated apart possible solar power . \n",
            "= saturn moon titan could power ussized colony study\n",
            "< us new new us us power <EOS>\n",
            "\n",
            "> study reveals apes understanding par human infants distinguishing whether person accurate belief situation mistaken .  experimenters locked certain objects box beside empty box front apes .  person trying locate objects apes pointed right box 76 . 5 time showing humanlike understanding . \n",
            "= apes separate true false beliefs others study\n",
            "< us man accused human us <EOS>\n",
            "\n",
            "> saudi arabia paid us military veterans attempt lobby recentlypassed law allowing families 911 attacks victims sue kindgom alleged role attacks reports said .  saudis reportedly hired 75 foreign agents across us fund trips veterans .  however veterans claimed misled trip organisers . \n",
            "= saudi arabia paid us soldiers protesting antisaudi law\n",
            "< us law military us military report us <EOS>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgSq_FJ00gF_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}